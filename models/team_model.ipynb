{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from scipy.stats import poisson\n",
    "from scipy.stats import norm\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EstimateParameters(fixture_list_1, fixture_list_2, fixture_list_3,\n",
    "                       teams, beta, thetapriormeans, thetapriorsds,\n",
    "                       niter=1000, log=False, temp=0, zerooutinds=np.array([])):\n",
    "    \n",
    "    # xdata and ydata are coordinates and y values of data\n",
    "    # xmodel are coordinates of model evaluations\n",
    "    # thetaprior are prior guesses for parameters\n",
    "    \n",
    "    # draw initial\n",
    "    if log:\n",
    "        if hasattr(thetapriormeans, '__len__'):\n",
    "            theta = np.zeros(len(thetapriormeans))\n",
    "            for i in range(len(thetapriormeans)):\n",
    "                theta[i] = np.exp(np.random.normal(thetapriormeans[i], thetapriorsds[i], 1))\n",
    "        else:\n",
    "            theta = np.exp(np.random.normal(thetapriormeans, thetapriorsds, 1))\n",
    "    else:\n",
    "        if hasattr(thetapriormeans, '__len__'):\n",
    "            theta = np.zeros(len(thetapriormeans))\n",
    "            for i in range(len(thetapriormeans)):\n",
    "                theta[i] = np.random.normal(thetapriormeans[i], thetapriorsds[i], 1)\n",
    "            # normalize\n",
    "            #theta[(len(teams) + 1 - 1)] = -np.sum(theta[1:(len(teams) + 1 - 1)])\n",
    "            #theta[((2 * len(teams)) + 1 - 1)] = -np.sum(theta[(len(teams) + 1):((2 * len(teams)) + 1 - 1)])\n",
    "        else:\n",
    "            theta = np.random.normal(thetapriormeans, thetapriorsds, 1)\n",
    "    \n",
    "    if hasattr(thetapriormeans, '__len__'):\n",
    "        thetaarray = np.zeros((niter, len(thetapriormeans)))\n",
    "    else:\n",
    "        thetaarray = np.zeros(niter)\n",
    "        \n",
    "    accept_count = 0\n",
    "    \n",
    "    for j in range(niter):\n",
    "        \n",
    "        # temperature\n",
    "        T = np.exp(-temp * ((i + 1) / niter))\n",
    "        \n",
    "        if log:\n",
    "            if hasattr(thetapriormeans, '__len__'):\n",
    "                thetastar = np.exp(np.log(theta) + np.random.normal(0, np.sqrt(beta), len(theta)))\n",
    "            else:\n",
    "                thetastar = np.exp(np.log(theta) + np.random.normal(0, np.sqrt(beta), 1))\n",
    "        else:\n",
    "            if hasattr(thetapriormeans, '__len__'):\n",
    "                ind = np.random.normal(0, np.sqrt(beta), len(theta))\n",
    "                # normalize\n",
    "                #ind[(len(teams) + 1 - 1)] = -np.sum(ind[1:(len(teams) + 1 - 1)])\n",
    "                #ind[((2 * len(teams)) + 1 - 1)] = -np.sum(ind[(len(teams) + 1):((2 * len(teams)) + 1 - 1)])\n",
    "                thetastar = theta + ind\n",
    "            else:\n",
    "                ind = np.random.normal(0, np.sqrt(beta), 1)\n",
    "                thetastar = theta + ind\n",
    "        \n",
    "        # get likelihood for each\n",
    "        mu = theta[0]\n",
    "        a = theta[1:(len(teams) + 1)]\n",
    "        d = theta[(len(teams) + 1):((2 * len(teams)) + 1)]\n",
    "        if len(zerooutinds) > 0:  # promoted team zero out\n",
    "            a[zerooutinds] = 0\n",
    "            d[zerooutinds] = 0\n",
    "        a[0] = - np.sum(a[1:])  # normalize\n",
    "        d[0] = - np.sum(d[1:])  # normalize\n",
    "        alpha = theta[((2 * len(teams)) + 1)]\n",
    "        Htheta = likelihood_three_seasons(fixture_list_1, fixture_list_2, fixture_list_3,\n",
    "                                          teams, mu, a, d, alpha)\n",
    "        \n",
    "        mu = thetastar[0]\n",
    "        a = thetastar[1:(len(teams) + 1)]\n",
    "        d = thetastar[(len(teams) + 1):((2 * len(teams)) + 1)]\n",
    "        if len(zerooutinds) > 0:  # promoted team zero out\n",
    "            a[zerooutinds] = 0\n",
    "            d[zerooutinds] = 0\n",
    "        a[0] = - np.sum(a[1:])  # normalize\n",
    "        d[0] = - np.sum(d[1:])  # normalize\n",
    "        alpha = thetastar[((2 * len(teams)) + 1)]\n",
    "        Hthetastar = likelihood_three_seasons(fixture_list_1, fixture_list_2, fixture_list_3,\n",
    "                                              teams, mu, a, d, alpha)\n",
    "        \n",
    "        alpha = np.min([0, (1 / T) * (Hthetastar - Htheta)])\n",
    "        \n",
    "        # sample uniformly\n",
    "        u = np.random.uniform(0, 1)\n",
    "        \n",
    "        # accept or not\n",
    "        accept = np.log(u) <= alpha\n",
    "        \n",
    "        if accept:\n",
    "            theta = thetastar\n",
    "            accept_count += 1\n",
    "            \n",
    "        if hasattr(thetapriormeans, '__len__'):\n",
    "            thetaarray[j, :] = theta\n",
    "            if (j%10) == 0:\n",
    "                print('------')\n",
    "                print('Iteration: ', str(j))\n",
    "                print('Home coefficient: '+str(thetaarray[j, 0]))\n",
    "                print('Arsenal attack coefficient: '+str(thetaarray[j, 1]))\n",
    "                print('acceptance ratio: ', accept_count / (j + 1))\n",
    "        else:\n",
    "            thetaarray[j] = theta\n",
    "    \n",
    "    # convert back and normalize\n",
    "    if hasattr(thetapriormeans, '__len__'):\n",
    "        if len(zerooutinds) > 0:  # zero out promoted teams\n",
    "            thetaarray[:, (1 + zerooutinds).astype(int)] = 0.\n",
    "            thetaarray[:, (1 + zerooutinds + len(teams)).astype(int)] = 0.\n",
    "        thetaarray[:, 1] = - np.sum(thetaarray[:, 2:(len(teams) + 1)], axis=1)\n",
    "        thetaarray[:, (len(teams) + 1)] = - np.sum(thetaarray[:, (len(teams) + 2):((2 * len(teams)) + 1)], axis=1)\n",
    "    \n",
    "    return thetaarray\n",
    "\n",
    "# create likelihood eval for one game\n",
    "def likelihood_one_game(goals_ht, goals_at, form_ht, form_at, mu, a_ht, d_ht, a_at, d_at, alpha):\n",
    "    lambda_ht = np.exp(mu + a_ht + d_at + (alpha * form_ht))\n",
    "    lambda_at = np.exp(a_at + d_ht + (alpha * form_at))\n",
    "    p1 = poisson.pmf(goals_ht, lambda_ht)\n",
    "    p2 = poisson.pmf(goals_at, lambda_at)\n",
    "    return(p1 * p2)\n",
    "\n",
    "# create likelihood eval for single season\n",
    "def likelihood_season(fixtures_list, teams, mu, a, d, alpha):\n",
    "    N = np.shape(fixtures_list)[0]\n",
    "    goals_ht = fixtures_list[:, 2]\n",
    "    goals_at = fixtures_list[:, 3]\n",
    "    teams_ht = fixtures_list[:, 0]\n",
    "    teams_at = fixtures_list[:, 1]\n",
    "    \n",
    "    teams_for_season = np.unique(teams_ht)\n",
    "    \n",
    "    points = np.zeros((38, 20))\n",
    "    team_count = np.zeros(20)\n",
    "    for i in range(N):\n",
    "        points[team_count[np.where(teams_for_season == teams_ht[i])[0][0].astype(int)].astype(int), np.where(teams_for_season == teams_ht[i])[0][0].astype(int)] = (3 * (goals_ht[i] > goals_at[i])) + (goals_ht[i] == goals_at[i])\n",
    "        points[team_count[np.where(teams_for_season == teams_at[i])[0][0].astype(int)].astype(int), np.where(teams_for_season == teams_at[i])[0][0].astype(int)] = (3 * (goals_ht[i] < goals_at[i])) + (goals_ht[i] == goals_at[i])\n",
    "        team_count[np.where(teams_for_season == teams_ht[i])[0][0].astype(int)] += 1\n",
    "        team_count[np.where(teams_for_season == teams_at[i])[0][0].astype(int)] += 1\n",
    "    form = np.ones((38, 20)) * 7.5\n",
    "    for j in range(20):\n",
    "        form[5:, j] = np.cumsum(points[:, j])[5:] - np.cumsum(points[:, j])[:(38 - 5)]\n",
    "    \n",
    "    team_count = np.zeros(20)\n",
    "    likelihood = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        ind_ht = np.where(teams == teams_ht[i])[0][0].astype(int)\n",
    "        ind_at = np.where(teams == teams_at[i])[0][0].astype(int)\n",
    "        ind_for_season_ht = np.where(teams_for_season == teams_ht[i])[0][0].astype(int)\n",
    "        ind_for_season_at = np.where(teams_for_season == teams_at[i])[0][0].astype(int)\n",
    "        l = likelihood_one_game(goals_ht[i], goals_at[i],\n",
    "                                form[team_count[ind_for_season_ht].astype(int), ind_for_season_ht].astype(int), form[team_count[ind_for_season_at].astype(int), ind_for_season_at],\n",
    "                                mu, a[ind_ht], d[ind_ht], a[ind_at], d[ind_at], alpha)\n",
    "        team_count[np.where(teams_for_season == teams_ht[i])[0][0].astype(int)] += 1\n",
    "        team_count[np.where(teams_for_season == teams_at[i])[0][0].astype(int)] += 1\n",
    "        likelihood[i] = l\n",
    "    \n",
    "    return(np.sum(np.log(likelihood)))\n",
    "\n",
    "# likelihood over three seasons - weighted\n",
    "def likelihood_three_seasons(fixture_list_1, fixture_list_2, fixture_list_3, teams, mu, a, d, alpha):\n",
    "    likelihood = (0.2 * likelihood_season(fixture_list_1, teams, mu, a, d, alpha)) + (0.3 * likelihood_season(fixture_list_2, teams, mu, a, d, alpha)) + (0.5 * likelihood_season(fixture_list_3, teams, mu, a, d, alpha))\n",
    "    return(likelihood)\n",
    "\n",
    "# function to predict probabilities of fixtures\n",
    "def predict_fixtures(new_fixtures, form, teams, mu, a, d, alpha, uncertainty=False):\n",
    "    if uncertainty:\n",
    "        # form is N x 2\n",
    "        N = np.shape(new_fixtures)[0]\n",
    "        teams_ht = new_fixtures[:, 0]\n",
    "        teams_at = new_fixtures[:, 1]\n",
    "        lambda_1 = np.zeros(N)\n",
    "        lambda_2 = np.zeros(N)\n",
    "        for i in range(N):\n",
    "            muest = np.random.normal(mu[0], mu[1])\n",
    "            aest = np.zeros(len(teams))\n",
    "            dest = np.zeros(len(teams))\n",
    "            for u in range(len(teams)):\n",
    "                aest[u] = np.random.normal(a[u, 0], a[u, 1])\n",
    "                dest[u] = np.random.normal(d[u, 0], d[u, 1])\n",
    "            alphaest = np.random.normal(alpha[0], alpha[1])\n",
    "            ind_ht = np.where(teams == teams_ht[i])[0][0].astype(int)\n",
    "            ind_at = np.where(teams == teams_at[i])[0][0].astype(int)\n",
    "            lambda_1[i] = np.exp(muest + aest[ind_ht] + dest[ind_at] + (alphaest * form[i, 0]))\n",
    "            lambda_2[i] = np.exp(aest[ind_at] + dest[ind_ht] + (alphaest * form[i, 1]))\n",
    "    else:\n",
    "        # form is N x 2\n",
    "        N = np.shape(new_fixtures)[0]\n",
    "        teams_ht = new_fixtures[:, 0]\n",
    "        teams_at = new_fixtures[:, 1]\n",
    "        lambda_1 = np.zeros(N)\n",
    "        lambda_2 = np.zeros(N)\n",
    "        for i in range(N):\n",
    "            ind_ht = np.where(teams == teams_ht[i])[0][0].astype(int)\n",
    "            ind_at = np.where(teams == teams_at[i])[0][0].astype(int)\n",
    "            lambda_1[i] = np.exp(mu + a[ind_ht] + d[ind_at] + (alpha * form[i, 0]))\n",
    "            lambda_2[i] = np.exp(a[ind_at] + d[ind_ht] + (alpha * form[i, 1]))\n",
    "    return(lambda_1, lambda_2)\n",
    "\n",
    "def import_fixture_lists(filename_1, filename_2, filename_3):\n",
    "    fixture_list_1 = pd.read_csv(filename_1, header=None)\n",
    "    fixture_list_2 = pd.read_csv(filename_2, header=None)\n",
    "    fixture_list_3 = pd.read_csv(filename_3, header=None)\n",
    "    return(fixture_list_1, fixture_list_2, fixture_list_3)\n",
    "\n",
    "def import_fixture_list(filename):\n",
    "    fixture_list = pd.read_csv(filename, header=None)\n",
    "    return(fixture_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixture_list_1, fixture_list_2, fixture_list_3 = import_fixture_lists(\"../data/prem_results_20162017.csv\",\n",
    "                                                                      \"../data/prem_results_20172018.csv\",\n",
    "                                                                      \"../data/prem_results_20182019.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# all teams in three seasons and fourth season\n",
    "team_list = np.concatenate((np.unique(fixture_list_1.as_matrix()[:, 0]),\n",
    "                            np.unique(fixture_list_2.as_matrix()[:, 0]),\n",
    "                            np.unique(fixture_list_3.as_matrix()[:, 0]),\n",
    "                            ((pd.read_csv(\"../data/team_id_20192020.csv\", header=0)).as_matrix())[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = np.unique(team_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl1 = fixture_list_1.as_matrix()\n",
    "fl2 = fixture_list_2.as_matrix()\n",
    "fl3 = fixture_list_3.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "a = np.ones(len(teams)) * 0.1\n",
    "d = np.ones(len(teams)) * 0.1\n",
    "mu = 0.1\n",
    "alpha = 0.1\n",
    "l = likelihood_season(fl1, teams, mu, a, d, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "predict_fixtures(fl1[1:3, :], np.array([[3, 3], [3, 3]]), teams, mu, a, d, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priormeans = np.ones((2 * len(teams)) + 2) * 0.0\n",
    "priorsds = np.ones((2 * len(teams)) + 2) * 0.1\n",
    "beta = 0.00025\n",
    "niter = 50000\n",
    "\n",
    "# prior-out promoted teams\n",
    "inds = list(np.where(teams == 'Norwich City')[0])\n",
    "inds.append(np.where(teams == 'Aston Villa')[0][0])\n",
    "inds.append(np.where(teams == 'Sheffield United')[0][0])\n",
    "inds = np.array(inds)\n",
    "\n",
    "est = EstimateParameters(fl1, fl2, fl3, teams, beta, priormeans, priorsds, niter=niter, zerooutinds=inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = 'Tottenham'\n",
    "plot.plot(est[:, (1 + np.where(teams == tm)[0][0]).astype(int)], 'r')\n",
    "plot.plot(est[:, (len(teams) + 1 + np.where(teams == tm)[0][0]).astype(int)], 'b')\n",
    "plot.show()\n",
    "\n",
    "plot.plot(est[:, 0], 'k')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save parameters\n",
    "burn = int((4 * niter) / 5)\n",
    "mu_mean = np.array([np.mean(est[burn:, 0])])\n",
    "mu_sd = np.array([np.std(est[burn:, 0])])\n",
    "a_mean = np.mean(est[burn:, 1:(len(teams) + 1)], axis=0)\n",
    "a_sd = np.std(est[burn:, 1:(len(teams) + 1)], axis=0)\n",
    "d_mean = np.mean(est[burn:, (len(teams) + 1):((2 * len(teams)) + 1)], axis=0)\n",
    "d_sd = np.std(est[burn:, (len(teams) + 1):((2 * len(teams)) + 1)], axis=0)\n",
    "alpha_mean = np.array([np.mean(est[burn:, ((2 * len(teams)) + 1)])])\n",
    "alpha_sd = np.array([np.std(est[burn:, ((2 * len(teams)) + 1)])])\n",
    "means = np.concatenate((mu_mean, a_mean, d_mean, alpha_mean))\n",
    "sds = np.concatenate((mu_sd, a_sd, d_sd, alpha_sd))\n",
    "\n",
    "sds[1 + inds] = 0.1\n",
    "sds[1 + len(teams) + inds] = 0.1\n",
    "\n",
    "with open('../parameters/all_teams.csv', mode='w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file, delimiter=',')\n",
    "    for tm in teams:\n",
    "        csv_writer.writerow([tm])\n",
    "csv_file.close()\n",
    "\n",
    "with open('../parameters/all_teams_params.csv', mode='w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file, delimiter=',')\n",
    "    for i in range(((2 * len(teams)) + 2)):\n",
    "        csv_writer.writerow([means[i], sds[i]])\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save parameters here, and either predict for whole next season or individual gameweeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create fixture list this season to predict\n",
    "fixture_list_this_season = []\n",
    "for i, fix in enumerate(list(itertools.permutations(((pd.read_csv(\"../data/team_id_20192020.csv\", header=0)).as_matrix())[:, 0], 2))):\n",
    "    fixture_list_this_season.append(list(fix))\n",
    "fixture_list_this_season = np.array(fixture_list_this_season)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update with week-by-week results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-requisits: read 'teams', and function import_fixture_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read this weeks results\n",
    "fixture_list_this_week = import_fixture_list(\"../data/prem_results_20182019.csv\")\n",
    "fixture_list_this_week = fixture_list_this_week.loc[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read params\n",
    "all_teams_params = pd.read_csv(\"../parameters/all_teams_params.csv\", header=None)\n",
    "\n",
    "# particles\n",
    "N = 1000\n",
    "tp = all_teams_params.as_matrix()\n",
    "params = np.zeros((np.shape(tp)[0], N))\n",
    "for j in range(np.shape(tp)[0]):\n",
    "    params[j, :] = np.random.normal(tp[j, 0], tp[j, 1], N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# particle filter likelihood\n",
    "xi = np.zeros(N)\n",
    "for i in range(N):\n",
    "    for j in range(len(fixture_list_this_week.index)):\n",
    "        a_ht = params[1 + np.where(teams == fixture_list_this_week.loc[fixture_list_this_week.index[j], 0])[0], i]\n",
    "        a_at = params[1 + np.where(teams == fixture_list_this_week.loc[fixture_list_this_week.index[j], 1])[0], i]\n",
    "        d_ht = params[1 + len(teams) + np.where(teams == fixture_list_this_week.loc[fixture_list_this_week.index[j], 0])[0], i]\n",
    "        d_at = params[1 + len(teams) + np.where(teams == fixture_list_this_week.loc[fixture_list_this_week.index[j], 1])[0], i]\n",
    "        xi[i] += np.log(likelihood_one_game(fixture_list_this_week.loc[fixture_list_this_week.index[j], 2],\n",
    "                                            fixture_list_this_week.loc[fixture_list_this_week.index[j], 3],\n",
    "                                            5, 5, params[0, i], a_ht, d_ht, a_at, d_at, params[-1, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled = np.random.choice(np.linspace(0, N - 1, N), N, p=np.exp(xi) / np.sum(np.exp(xi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_params = params[:, resampled.astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_means = np.mean(resampled_params, axis=1)\n",
    "new_sds = np.std(resampled_params, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('../parameters/all_teams_params.csv', mode='w', newline='') as csv_file:\n",
    "#    csv_writer = csv.writer(csv_file, delimiter=',')\n",
    "#    for i in range(((2 * len(teams)) + 2)):\n",
    "#        csv_writer.writerow([new_means[i], new_sds[i]])\n",
    "#csv_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulate seasons performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wins = np.zeros(20)\n",
    "topfour = np.zeros(20)\n",
    "niter = 1000\n",
    "\n",
    "# predict lambdas - average form\n",
    "muest = np.hstack((means[0], sds[0]))\n",
    "aest = np.hstack((np.reshape(means[1:(1+len(teams))], ((len(teams), 1))),\n",
    "                  np.reshape(sds[1:(1+len(teams))], ((len(teams), 1)))))\n",
    "dest = np.hstack((np.reshape(means[(1+len(teams)):(1+(2*len(teams)))], ((len(teams), 1))),\n",
    "                  np.reshape(sds[(1+len(teams)):(1+(2*len(teams)))], ((len(teams), 1)))))\n",
    "alphaest = np.hstack((means[((2 * len(teams)) + 1)], sds[((2 * len(teams)) + 1)]))\n",
    "\n",
    "for j in range(niter):\n",
    "    # work out total goals predicted\n",
    "    total_goals = np.zeros(20)\n",
    "    #actual_goals = np.zeros(20)\n",
    "    total_goals_conceded = np.zeros(20)\n",
    "    #actual_goals_conceded = np.zeros(20)\n",
    "    tms = np.unique(fixture_list_this_season[:, 0])\n",
    "    goals_this_season = predict_fixtures(fixture_list_this_season, np.ones((380, 2)) * 5, teams, muest, aest, dest, alphaest, uncertainty=True)\n",
    "    pnts = np.zeros(20)\n",
    "    for i in range(np.shape(fixture_list_this_season)[0]):\n",
    "        goals_ht = np.random.poisson(goals_this_season[0][i])\n",
    "        goals_at = np.random.poisson(goals_this_season[1][i])\n",
    "        total_goals[np.where(tms == fixture_list_this_season[i, 0])[0][0].astype(int)] += goals_ht\n",
    "        total_goals[np.where(tms == fixture_list_this_season[i, 1])[0][0].astype(int)] += goals_at\n",
    "        pnts[np.where(tms == fixture_list_this_season[i, 0])[0][0].astype(int)] += ((goals_at < goals_ht) * 3) + (goals_at == goals_ht)\n",
    "        pnts[np.where(tms == fixture_list_this_season[i, 1])[0][0].astype(int)] += ((goals_at > goals_ht) * 3) + (goals_at == goals_ht)\n",
    "        #actual_goals[np.where(tms == fl2[i, 0])[0][0].astype(int)] += fl2[i, 2]\n",
    "        #actual_goals[np.where(tms == fl2[i, 1])[0][0].astype(int)] += fl2[i, 3]\n",
    "        total_goals_conceded[np.where(tms == fixture_list_this_season[i, 0])[0][0].astype(int)] += goals_at\n",
    "        total_goals_conceded[np.where(tms == fixture_list_this_season[i, 1])[0][0].astype(int)] += goals_ht\n",
    "        #actual_goals_conceded[np.where(tms == fl2[i, 0])[0][0].astype(int)] += fl2[i, 3]\n",
    "        #actual_goals_conceded[np.where(tms == fl2[i, 1])[0][0].astype(int)] += fl2[i, 2]\n",
    "    # update title wins\n",
    "    wins[np.argmax(pnts)] += 1\n",
    "    # update top four finishes\n",
    "    topfour[np.argsort(pnts)[16:]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.arange(len(topfour))  # the x locations for the groups\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plot.subplots()\n",
    "rects1 = ax.bar(ind - width/2, wins/niter, width,\n",
    "                label='Wins')\n",
    "rects2 = ax.bar(ind + width/2, topfour/niter, width,\n",
    "                label='Top Four')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(tuple(tms))\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tms)\n",
    "print(wins/niter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tms)\n",
    "print(total_goals)\n",
    "print(total_goals_conceded)\n",
    "print(total_goals - total_goals_conceded)\n",
    "print(np.argsort(pnts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
